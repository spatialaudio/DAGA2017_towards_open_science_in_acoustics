\documentclass[a4paper, 10pt, twocolumn]{article}

\usepackage[utf8]{inputenc}         
\usepackage{graphicx}
\usepackage{url}
\usepackage[small,bf]{caption2}
\usepackage{parskip}
\usepackage{titlesec}
\usepackage{amsmath, amssymb}
\usepackage[multiple]{footmisc}

\titleformat{\section}{\normalfont\large\bfseries}{\thesection}{}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesection}{}{}
\titleformat{\paragraph}{\normalfont\bfseries}{\theparagraph}{}{}
\titlespacing{\section}{0pt}{6pt}{-1pt}
\titlespacing{\subsection}{0pt}{3pt}{-1pt}
\titlespacing{\paragraph}{0pt}{3pt}{-1pt}

% Definition der Seitenränder
\addtolength{\textwidth}{2.1cm}
\addtolength{\topmargin}{-2.4cm}
\addtolength{\oddsidemargin}{-1.1 cm}
\addtolength{\textheight}{4.5cm}
\setlength{\columnsep}{0.7cm}

\pagestyle{empty}                   % weder Kopf- noch Fußzeile auf 1. Seite


\date{}                                         % kein Datum auf 1. Seite

\title{\vspace{-8mm}\textbf{\large
Towards Open Science in Acoustics: Foundations and Best Practices}}

% Hier die Namen und Daten der beteiligten Autoren eintragen
\author{
Sascha Spors$^1$, Matthias Geier$^1$ and Hagen Wierstorf$^2$\\
$^1$ \emph{\small Institute of Communications Engineering, University of Rostock, Germany, Email: sascha.spors@uni-rostock.de}\\
$^2$ \emph{\small Filmuniversität Babelsberg KONRAD WOLF}} 


% ================================================================================
% ================================================================================
\begin{document}

\maketitle
\thispagestyle{empty}           % weder Kopf- noch Fußzeile auf Folgeseiten

% ================================================================================
\section*{The Scientific Method} \label{sec:intro} 

Before introducing the open science approach in detail its worthwhile to review the
foundations of the scientific method. It may be referred to  as 
\emph{'A method of procedure that has characterized natural science since the 17th 
century, consisting in systematic observation, measurement, and experiment, and the 
formulation, testing, and modification of hypotheses.'}~\cite{scientific_method:OXD}. 
Science builds upon a set of well accepted methods which are commonly believed to
ensure above formulated principles. Besides these, the reproducibility of results is 
one of the cornerstones of the scientific method. 
It may be defined as \emph{'Reproducibility is the ability of an entire analysis of 
an experiment or study to be duplicated, either by the same researcher or by someone 
else working independently, whereas reproducing an experiment is called replicating 
it.'}~\cite{Leek15:PNAS}. 
The irreproducibility of a wide range of scientific results has drawn significant 
attention in the last decade~\cite{Borgwardt:Book,retraction:WWW,ioannidis05:PLOS, open15:AAAS, chalmers09:OG, freedman15:PLOS, howells14:Nature}. 
In order to track down the problem of irreproducibility the application areas of 
the scientific method have been classified into three branches~\cite{Donoho:CSE,Stodden2014:talk}:
\begin{enumerate}
\item deductive
\item empirical
\item computational
\end{enumerate}
The deductive branch covers results derived e.g. by formal logic and mathematics, the empirical
branch e.g. statistical analysis of controlled experiments. The first two are traditional branches, 
while the last one is considered as a potentially novel branch. It covers results derived by large-scale simulations
and data-driven computational science. The measures that have to be taken to ensure reproducibilitly
in the traditional are quite well known. This does not hold for the third, computational, branch.

Besides problems in the research methods themselves, results are often not reproducible since 
necessary supplementary material as protocols, data and implementations are not available. In 
many cases only the published results are accessible to other researchers. Open science 
focuses on the ease of access of scientific data underlying research and therefore supports the ease of reproducibility.

An alternative view on the problem of reproducibility is given by asking 
\textbf{who should benefit from my research}? Potential answers to this question ordered by 
the degree of transparency are:
\begin{itemize}
\item[$\square$] myself
\item[$\square$] my future self
\item[$\square$] my colleagues
\item[$\square$] other researchers
\item[$\square$] all people in the world
\item[$\square$] science itself
\end{itemize}
While research conducted for myself does not require any transparency in terms
of underlying data, research performed for the sake of science itself should be
as open as possible to encourage scientific advancement.


% ================================================================================
\section*{Open Science} \label{sec:open_science} 

Open science follows the general demand for socialization of knowledge. More specifically, 
it aims at making the research process transparent on all levels. The advent of scientific 
journals can be seen as a first step towards openness. Open Science has been discussed on
a broad level in the last decade. However the exact meaning of the term is still not fully 
settled. Many measures are discussed to achieve transparency in the research process~\cite{Pontika15:ACM,Reproducibility15:AMS,Albagli15:Book,Vrana15:MIPRO,Kraker11:TEL}. 
We review the most common elements of open science in the following, followed by application 
examples in the context of a listening experiment.


% ................................................................................
\paragraph*{Elements of Open Science}

The various measures used to gain open and transparent science may be classified as
follows:
\begin{itemize}
\item \textbf{Open Source}\\
Availability of source code of the implementations used in the research process, e.g. 
for numerical simulations, statistical analyses and graphical user interfaces.
%
\item \textbf{Open (Science) Data}\\
Availability of the data underlying the research, whereas data does not only refer 
to electronic resources but also to protocols, material samples, etc. For instance
impulse responses, anechoic stimuli and anthropomorphic data.
%
\item \textbf{Open Access}\\
Free access to published research output, e.g. articles.
%
\item \textbf{Open Methodology}\\
Detailed documentation of the methodology underlying the research. For instant hypothesis 
and experimental procedure.
%
\item \textbf{Open Notebook Science}\\
Availability of the primary record of research results, e.g. laboratory notebooks or 
detailed mathematical derivations.
%
\item \textbf{Open Educational Resources}\\
Freely accessible resources for teaching, learning and research. For instance textbooks, slides and
examples.
%
\item \textbf{Open Peer Review}~\cite{Ford13:LFP}\\
Various measures to increase the transparency of the peer review process, e.g. availability of 
review comments and crowdsourced review.
\end{itemize}


% ................................................................................
\paragraph*{Example -- Listening Experiment}

The workflow of a typical perceptual experiment serves as an example for the usage of 
the different elements of open science. A perceptual study may be decomposed into the
following stages:

\begin{enumerate}
\item \textbf{Idea}\\
The results of a preceding experiment or a discussion among colleagues is often the advent 
for new research projects. These ideas reveal for instance the motivation behind the research. 
Publishing the ideas as \underline{Open Notebook Science} makes them accessible to the public.
%
\item \textbf{Design of Experiment}\\
The experiment is designed on basis of the initial idea. This involves for instance the formulation 
of a hypothesis, the definition of a procedure, stimuli and subjects. \underline{Open Methodology} makes
the design available.
%
\item\textbf{Computation}\\
The generation of stimuli may involve mathematical deviations for numerical simulations, the 
implementation of signal processing, control logic and graphical user interface, as well as input data. These
can be made available in the sake of \underline{Open Notebook Science}, \underline{Open Data} and \underline{Open Source}.
%
\item \textbf{Experiment}\\
The experiment is then conducted in the next step and the responses are collected from the test subject. This
constitutes raw data which is processed later. The data can be published as \underline{Open Data} as long as
no privacy issues are raised.
%
\item \textbf{Analysis}\\
The statistical analysis of the raw data is the basis of the generalization of the individual results. This may
involve the anonymization and outlier removal as first steps. The analysis can be published using the elements
\underline{Open Methodology}, \underline{Open Source} and \underline{Open Data}.
%
\item \textbf{Manuscript}\\
The design and the results of the perceptual study are compiled into a manuscript for publication. It is composed
from text, references and visualization of the analyzed results. The manuscript may be published as \underline{Open Access}.
%
\item \textbf{Pre-Publication Peer Review}\\
The publication process typically involves some kind of quality assessment. The manuscript is evaluated by
independent researchers who provide ratings and suggestions for improvement. If accepted the manuscript is
the revised on this basis. The peer review process can be made transparent using the elements of \underline{Open Peer Review}.
%
\item \textbf{Publication}\\
After successful incorporation of comments from the pre-publication peer review the manuscript is ready for
publication. It may be accompanied by supplementary material in order to improve the ease of reproducibility. In the
case of conference papers a presentation may be given which contains other or additional. The elements involved
for publication are \underline{Open Access}, \underline{Open Source} and \underline{Open Data}.
%
\item \textbf{Aftermath}\\
After publication, the presented research may be replicated by others. Post-publication
review will rate the significance of the research. Feedback from this
may require to publish an errata or revise the underlying data and code. Finally open questions
may bring up ideas for the next research project.
\end{enumerate}


% ================================================================================
\section*{Copyright and Licenses} \label{sec:copyright}

Licenses are an important aspect of open science. Scientific data that is made 
available to the public has to be accompanied by a clear license statement. Otherwise
the situation concerning copyright and reuse is unclear. The legal implications are
rather complex, hard to oversee and country dependent in this case. The community offers
a wide variety of licensing frameworks which are of use for open science. In general different 
licenses are used for data, text, images, artwork and code. For the former the family of 
creative commons (CC) licenses~\cite{CC} is a good choice~\cite{Kreuzer14:Book}. For the
latter various license models are used, for instance the GNU General Public License (GPL), 
BSD or MIT License, to name a few.

The chosen license model should be as less restrictive as possible in order to promote the
re-use. In order to aid in the selection of an appropriate licensing strategy, recommendations
for open science have been given~\cite{Stodden09:CSE,}.


% ================================================================================
\section*{Management of Research Data} \label{sec:data_management}

The systematic management of research data is an important prerequisite for open and 
reproducible science. This covers the internal as well as public handling of data, whereas
the term research data is not restricted to electronic resources. The following principles
for research data management have been compiled from the recommendations given 
in~\cite{DFG_GWP:Book,HRK_FDM:WWW,Stodden2014:JORS,H2020_FAIR:ERC}
\begin{itemize}
\item develop a comprehensive data management plan
\item use workflow tracking in the research process
\item make data findable, accessible, interoperable and reusable (FAIR)~\cite{H2020_FAIR:ERC}
\item apply open licensing models
\item offer training and qualification
\end{itemize}
The data management should document the data raised and processed, its handling and
archival. The use of workflow tracking (e.g. SVN, git) makes the research process transparent 
and allows to discover for instance the source of problems. The FAIR policy in conjunction with
open licensing models promotes the re-use of published data. Training and qualification is an
essential cornerstone of an advanced data management strategy. It should highlight the importance
of data management and should introduce the data management plan as well as the tools used for
its realization.

Note, the instantiation of appropriate data management measures is mandatory in a number 
of funding schemes.


% ================================================================================
\section*{Conclusions} \label{sec:conclusions} 

% ................................................................................
\paragraph*{Empirical Analysis of Open Science}

Open science has been evaluated in a number of empirical studies. This covers the
actual state with respect to data publications up to the impact of open access 
publications. The current policy of journals has for instance been evaluated in~\cite{Stodden2013:PLOS1,Alsheikh11:PLOS}. The studies reveal that so far there is 
no common call for sharing code and data, and that the requirements are rather 
homogeneous. The offer to deposit underlying data and code is taken only by a minority
of authors.

The barriers and incentives of open source and data publications accompanying 
publications have been raised in a questionnaire within the machine learning 
community~\cite{}.

Various studies have investigated the presumed advantage in terms of citations of
open access publications, e.g.~\cite{Swan10:study,McCabe14:EI}. An clear advantage 
could be shown in most cases and no advantage in rare cases.

% ................................................................................
\paragraph*{Personal Experience}

Besides using open toolboxes and datasets our own expertise with open science began 
with the public release of the SoundScape Renderer (SSR)~\cite{Geier07:DEGA} in 
2010\footnote{\url{https://github.com/SoundScapeRenderer}}. Since then various software toolboxes, 
datasets, open access papers and open educational resources have been 
published\footnote{\url{https://github.com/spatialaudio}}\footnote{\url{https://github.com/sfstoolbox}}. 
We use Redmine, SVN and git for internal data management. Public releases are mainly
done on github and referenced by zenodo if required. Challenges were the initial
effort to get familiar with the workflow and license models. We furthermore did not find
a convenient solution for version tracking of large databases, for instance room 
acoustic measurements. A clear benefit is the need for documentation, clean-up and internal
discussion before releasing data to the public. While this effort seems to be undesirable at
first glance, it turns out to safe a lot of effort later on. The feedback from the community
is very positive and a number of bugs have been found. It can be expected that publicity 
released scientific code and data contains less bugs than we used internally only. 

A common concern often raised by others is the misuse of openly published data by others, 
for instance for commercial activities. So far we have not seen any misuse of our
materials and hence cannot confirm this concern.

% ................................................................................
\paragraph*{Conclusions}

We have introduced the concept of open science and discussed its application in the
field of acoustics. The reproducibility of results is an essential cornerstone of
the scientific method. Open science by itself does not ensure the ease of reproducibility of
published results. For instance the accessibility of code for a numeric simulation without
proper documentation can be very limited and may lead to irreproducibility of the simulation results. The FAIR policy~\cite{H2020_FAIR:ERC} (\emph{make data findable, accessible, interoperable and reusable}) of the EC is a first step towards quality standards for 
data publications. Other initiatives define minimum quality standards for data publications 
or have instantiated a peer-review for the reproducibility of published findings~\cite{}.  

Training and qualification has to be understood as an integral part of research data management and open science. It should convey its foundations as well as common tools and workflows.

The current movement towards open science is still in a phase of development and 
consolidation. The scientific ecosystem, for instance journals and funding organizations, 
has taken up the topic in order to improve the management of research data and the reproducibility of scientific findings. However, at the current state most institutional evaluation measures do not account for an engagement in open science. This is strongly 
linked to the problem of personal attribution when contributing to public developments and datasets. The scientific track record nowadays builds heavily on such measures as 
citation index and third party funding which potentially contradict the involvement into 
open science.


%================================================================================
% Bibliography
%================================================================================
{
\bibliographystyle{IEEEtran}
\bibliography{open_science,my}
}


\end{document}